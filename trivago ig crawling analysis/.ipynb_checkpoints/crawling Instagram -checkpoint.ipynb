{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN REFERENCE\n",
    "2019/ 09 \n",
    "\n",
    "https://cloud.tencent.com/developer/article/1339809\n",
    "\n",
    "her code is the only one work well probably bcs it's most recent one, but it's mainly about scraping photo. I mainly use it to modify the others' connection method\n",
    "\n",
    "2018/ 09\n",
    "\n",
    "https://github.com/hilqiqi0/crawler/blob/master/simple/instagram/instagram.py\n",
    "\n",
    "(X-Instagram-GIS is no longer applicable)\n",
    "\n",
    "I took the structure of extracting data from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from pyquery import PyQuery as pq\n",
    "import hashlib\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://www.instagram.com/'\n",
    "uri = 'https://www.instagram.com/graphql/query/?query_hash=a5164aed103f24b03e7b7747a2d94e3c&variables=%7B%22id%22%3A%22{user_id}%22%2C%22first%22%3A12%2C%22after%22%3A%22{cursor}%22%7D'\n",
    "\n",
    "headers = {\n",
    "'Connection':'keep-alive',\n",
    "'Host':'www.instagram.com',\n",
    "'Referer':'https://www.instagram.com/instagram/',\n",
    "'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36',\n",
    "'X-Requested-With':'XMLHttpRequest'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            print('url incorrect, error code', response.status_code)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def get_json(headers,url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print('website js incorrect, error code', response.status_code)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(60 + float(random.randint(1, 4000))/100)\n",
    "        return get_json(headers,url)\n",
    "\n",
    "\n",
    "\n",
    "def get_samples(html, users):\n",
    "\n",
    "    with open('{0}.txt'.format(users), 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        w = csv.writer(csvfile, delimiter=';')\n",
    "        user_id = re.findall('\"profilePage_([0-9]+)\"', html, re.S)[0]\n",
    "        i = 0\n",
    "        doc = pq(html)\n",
    "        items = doc('script[type=\"text/javascript\"]').items()\n",
    "        for item in items:\n",
    "            \n",
    "            if item.text().strip().startswith('window._sharedData'):\n",
    "                # window._sharedData 的内容转换为字典\n",
    "                js_data = json.loads(item.text()[21:-1], encoding='utf-8')\n",
    "                \n",
    "                # 12 张初始页面图片信息\n",
    "                edges = js_data[\"entry_data\"][\"ProfilePage\"][0][\"graphql\"][\"user\"][\"edge_owner_to_timeline_media\"][\"edges\"]\n",
    "                # 网页页面信息\n",
    "                page_info = js_data[\"entry_data\"][\"ProfilePage\"][0][\"graphql\"][\"user\"][\"edge_owner_to_timeline_media\"]['page_info']\n",
    "                # 下一页的索引值AQCSnXw1JsoV6LPOD2Of6qQUY7HWyXRc_CBSMWB6WvKlseC-7ibKho3Em0PEG7_EP8vwoXw5zwzsAv_mNMR8yX2uGFZ5j6YXdyoFfdbHc6942w\n",
    "                cursor = page_info['end_cursor']\n",
    "                # 是否有下一页\n",
    "                flag = page_info['has_next_page']\n",
    "                \n",
    "                # 节点信息筛选\n",
    "                for edge in edges:               \n",
    "                    \n",
    "                    # 如果是视频直接跳过\n",
    "                    if edge['node']['is_video'] == \"true\":\n",
    "                        continue\n",
    "                    \n",
    "                    time.sleep(1)\n",
    "                    # 图片信息筛选\n",
    "                    if edge['node']['display_url']:\n",
    "                        img_url= edge['node']['display_url']\n",
    "                        comment_count = edge['node']['edge_media_to_comment'][\"count\"]\n",
    "                        like_count = edge['node']['edge_liked_by'][\"count\"] \n",
    "              \n",
    "    \n",
    "                    if edge['node']['shortcode']:\n",
    "                        shortcode = edge['node']['shortcode']\n",
    "                        textUrl = 'https://www.instagram.com/p/' + shortcode + '/?__a=1'\n",
    "                        textRespose = get_json(headers,textUrl)\n",
    "                        textDict = textRespose['graphql']['shortcode_media']['edge_media_to_caption']['edges'][0]['node']\n",
    "                        text = str(textDict)[10:-2]\n",
    "                        re.sub('[;]', '', text)\n",
    "\n",
    "\n",
    "                    i += 1\n",
    "                    print('{0}th of {1} data written'.format(i, users))\n",
    "                    re.sub('[;]', '', img_url)\n",
    "                    w.writerow([users, img_url,  comment_count, like_count, text])                    \n",
    "                    \n",
    "                print(cursor, flag)\n",
    "                \n",
    "        # AJAX 请求更多信息                     \n",
    "        while flag:\n",
    "            url = uri.format(user_id=user_id, cursor=cursor)\n",
    "            queryVariables = '{\"id\":\"' + user_id + '\",\"first\":12,\"after\":\"' +cursor+ '\"}'\n",
    "            js_data = get_json(headers,url)\n",
    "            infos = js_data['data']['user']['edge_owner_to_timeline_media']['edges']\n",
    "            cursor = js_data['data']['user']['edge_owner_to_timeline_media']['page_info']['end_cursor']\n",
    "            flag = js_data['data']['user']['edge_owner_to_timeline_media']['page_info']['has_next_page']\n",
    "            \n",
    "            for info in infos:\n",
    "                if info['node']['is_video']:\n",
    "                    continue\n",
    "                else:\n",
    "\n",
    "                    img_url = info['node']['display_url']\n",
    "                    comment_count = info['node']['edge_media_to_comment'][\"count\"]\n",
    "                    like_count = info['node']['edge_media_preview_like'][\"count\"]                    \n",
    "                                                            \n",
    "                    if info['node']['shortcode']:\n",
    "                        time.sleep(1)\n",
    "                        shortcode = info['node']['shortcode']\n",
    "                        textUrl = 'https://www.instagram.com/p/' + shortcode + '/?__a=1'\n",
    "                        textRespose = get_json(headers,textUrl)   \n",
    "                        textDict = textRespose['graphql']['shortcode_media']['edge_media_to_caption']['edges'][0]['node']\n",
    "                        text = str(textDict)[10:-2]\n",
    "                        re.sub('[;]', '', text)\n",
    "\n",
    "                        i += 1\n",
    "                        print('{0}th of {1} data written'.format(i, users))\n",
    "                        re.sub('[;]', '', img_url)\n",
    "                        w.writerow([users, img_url,  comment_count, like_count, text])                    \n",
    "\n",
    "                    \n",
    "            print(cursor, flag)\n",
    "            \n",
    "            if i > 1000:\n",
    "                break\n",
    "\n",
    "    print('complete')\n",
    "    csvfile.close()\n",
    "\n",
    "\n",
    "def main(user):\n",
    "    url = url_base + user + '/'\n",
    "    html = get_html(url)\n",
    "    samples = get_samples(html, user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['trivago', 'bookingcom', 'tripadvisor','airbnb', 'expedia']\n",
    "for i in  range(len(target)):\n",
    "    user_name = target[i]\n",
    "#     main(user_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I list out all the post I tried when attempting to scrape insta \n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "most problem should be resulted from compatability(or maybe just me misusing it)\n",
    "\n",
    "it's undoubt all of these coder are way better than me\n",
    "\n",
    "\n",
    "2018/10\n",
    "\n",
    "https://github.com/Mrrrrr10/Instagram_Spider\n",
    "\n",
    "X-Instagram-GIS is no longer applicable\n",
    "\n",
    "instruction is very confusing to ppl knows nothing about crawling like me\n",
    "\n",
    "\n",
    "2019/01\n",
    "\n",
    "http://anddymao.com/2019/01/29/2019-1-29-python%E7%88%AC%E8%99%AB%E6%8A%93%E5%8F%96instagram%E4%BF%A1%E6%81%AF/\n",
    "\n",
    "I can't reach firefox selenium.webdriver might be path issue, but the code's not easy to comprehend in the first place\n",
    "\n",
    "\n",
    "2019/06\n",
    "\n",
    "https://github.com/luengwaiban/instagram-python-scraper\n",
    "\n",
    "limited field \n",
    "\n",
    "\n",
    "2018/05\n",
    "\n",
    "https://github.com/LevPasha/Instagram-API-python\n",
    "\n",
    "for personal account management\n",
    "\n",
    "\n",
    "2019/09\n",
    "\n",
    "https://github.com/huaying/instagram-crawler\n",
    "\n",
    "Taiwanese fellow here but there are a lot of field in the function can't be fetched as it should, and posts_full simply doesn't work\n",
    "\n",
    "\n",
    "2019/11\n",
    "\n",
    "https://github.com/timgrossmann/instagram-profilecrawl\n",
    "\n",
    "path problem with webdriver and after one successful attemp the code crashed, limited field\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
